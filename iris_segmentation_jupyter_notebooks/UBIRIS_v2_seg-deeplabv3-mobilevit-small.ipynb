{"cells":[{"cell_type":"code","source":["# Google Colab\n","# Install huggingface pytorch version transformers packages\n","from IPython.display import clear_output\n","!pip install transformers\n","clear_output()"],"metadata":{"id":"GI4gB0k5ZexU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5q7zn0LWr-HL"},"outputs":[],"source":["# PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# Huggingface Pytorch Transformers\n","import transformers\n","from transformers import MobileViTFeatureExtractor, MobileViTForSemanticSegmentation, get_linear_schedule_with_warmup\n","\n","# albumentations\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# OpenCV\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","# Others\n","import os\n","import math\n","from PIL import Image\n","from tqdm import tqdm\n","\n","from collections import defaultdict\n","import random\n","import numpy as np\n","import pandas as pd\n","\n","%matplotlib inline\n","import matplotlib\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["Only works on Colab"],"metadata":{"id":"_ZrDp5bkIScK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-44KjxC8bIL"},"outputs":[],"source":["import os\n","from google.colab import drive\n","# Google Colab with Personal Google Drive\n","drive.mount('/content/drive')\n","# Change to project folder\n","path = r\"/content/drive/MyDrive/COMP6200 Master Project\"\n","os.chdir(path)\n","os.path.abspath(os.curdir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCV_AaU-o8TJ"},"outputs":[],"source":["# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","print(torch.__version__)\n","print(torch.cuda.is_available())\n","\n","if torch.cuda.is_available():\n","  print(torch.cuda.device_count())\n","  print(torch.cuda.get_device_name(0))"]},{"cell_type":"markdown","source":["# Iris Segmentation Datasets"],"metadata":{"id":"kWhwgYj0HymF"}},{"cell_type":"markdown","source":["## Preprocessing"],"metadata":{"id":"YLlYuksFKPWt"}},{"cell_type":"code","source":["def binary_the_mask(mask_path):\n","  mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","  _, mask_binary = cv2.threshold(mask, 127, 1, cv2.THRESH_BINARY)\n","  mask_binary = mask_binary.astype(np.uint8)\n","\n","  return mask_binary\n","\n","class DatasetSeg(Dataset):\n","\n","    def __init__(self, root, dataset_name, transform=None):\n","        self.root = root\n","        self.dataset_name = dataset_name\n","        self.images_dir = 'image'\n","        self.masks_dir = 'SegmentationClass'\n","\n","        self.images_path = os.path.join(self.root, self.images_dir)\n","        self.masks_path = os.path.join(self.root, self.masks_dir)\n","        self.images_list = list(os.listdir(self.images_path))\n","        self.masks_list = list(os.listdir(self.masks_path))\n","\n","        self.transform = transform\n","\n","\n","    def __len__(self):\n","      return len(self.images_list) # how many pictures\n","  \n","    def __getitem__(self, idx):\n","        image_filename = self.images_list[idx].split('.')[0]\n","\n","        if self.dataset_name == 'CASIA-Iris-Africa' or self.dataset_name == 'CASIA-Iris-Asia/CASIA-distance':\n","          image = cv2.imread(os.path.join(self.images_path, (image_filename + '.JPEG')), cv2.IMREAD_UNCHANGED)\n","          mask = cv2.imread(os.path.join(self.masks_path, (image_filename +'.png')), cv2.IMREAD_UNCHANGED)\n","          mask_binary = binary_the_mask(os.path.join(self.masks_path, (image_filename +'.png')))\n","\n","        if self.dataset_name == 'CASIA-Iris-Asia/CASIA-Iris-Complex/Occlusion' or self.dataset_name == 'CASIA-Iris-Asia/CASIA-Iris-Complex/Off_angle':\n","          image = cv2.imread(os.path.join(self.images_path, (image_filename + '.jpg')), cv2.IMREAD_UNCHANGED)\n","          mask = cv2.imread(os.path.join(self.masks_path, (image_filename +'.png')), cv2.IMREAD_UNCHANGED)\n","          mask_binary = binary_the_mask(os.path.join(self.masks_path, (image_filename +'.png')))\n","\n","        if self.dataset_name == 'CASIA-Iris-Asia/CASIA-Iris-M1':\n","          image = cv2.imread(os.path.join(self.images_path, (image_filename + '.JPG')), cv2.IMREAD_UNCHANGED)\n","          mask = cv2.imread(os.path.join(self.masks_path, (image_filename +'.png')), cv2.IMREAD_UNCHANGED)\n","          mask_binary = binary_the_mask(os.path.join(self.masks_path, (image_filename +'.png')))\n","\n","        if self.dataset_name == 'UBIRIS_v2_seg':\n","          image = cv2.imread(os.path.join(self.images_path, (image_filename + '.tiff')), cv2.IMREAD_UNCHANGED)\n","          mask = cv2.imread(os.path.join(self.masks_path, (image_filename +'.tiff')), cv2.IMREAD_UNCHANGED)\n","          mask_binary = binary_the_mask(os.path.join(self.masks_path, (image_filename +'.tiff')))\n","\n","        if self.dataset_name =='MICHE_seg':\n","          image = cv2.imread(os.path.join(self.images_path, (image_filename + '.JPEG')), cv2.IMREAD_UNCHANGED)\n","          mask = cv2.imread(os.path.join(self.masks_path, (image_filename +'.png')), cv2.IMREAD_UNCHANGED)\n","          mask_binary = binary_the_mask(os.path.join(self.masks_path, (image_filename +'.png')))\n","\n","        if self.transform is not None:\n","          augmentation = self.transform(image=image, mask=mask_binary)\n","          image_aug = augmentation['image']\n","          mask_binary_aug = augmentation['mask']\n","          return image_aug, mask_binary_aug\n","\n","        return image, mask_binary\n","\n","class DatasetAfterSplit(Dataset):\n","    def __init__(self, subset, transform=None):\n","        self.subset = subset\n","        self.transform = transform\n","\n","    def __getitem__(self, idx):\n","        image, mask_binary = self.subset[idx]\n","\n","        if self.transform is not None:\n","          augmentation = self.transform(image=image, mask=mask_binary)\n","          image_aug = augmentation['image']\n","          mask_binary_aug = augmentation['mask']\n","          return image_aug, mask_binary_aug\n","\n","        return image, mask_binary\n","\n","    def __len__(self):\n","        return len(self.subset)\n","\n","\n","class DatasetMaskTransform(Dataset):\n","    def __init__(self, subset, transform=None):\n","        self.subset = subset\n","        self.transform = transform\n","\n","    def __getitem__(self, idx):\n","        image, mask_binary = self.subset[idx]\n","\n","        if self.transform is not None:\n","          image = ToTensorV2()(image=image)['image']\n","          augmentation = self.transform(image=mask_binary)\n","          mask_binary_aug = augmentation['image']\n","          return image, mask_binary_aug\n","        \n","        return image, mask_binary\n","\n","    def __len__(self):\n","        return len(self.subset)"],"metadata":{"id":"J3zFIIJ2UZe2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["size = (400,400)\n","resize_transform = A.Compose(\n","    [\n","        A.Resize(height=size[0], width=size[1], interpolation=cv2.INTER_NEAREST),\n","    ]\n",")\n","UBIRIS_v2_seg_train = DatasetSeg('./data/UBIRIS_v2_seg/train', 'UBIRIS_v2_seg', transform=resize_transform)\n","UBIRIS_v2_seg_test = DatasetSeg('./data/UBIRIS_v2_seg/test', 'UBIRIS_v2_seg', transform=resize_transform)"],"metadata":{"id":"Zbtq8PNr5oRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_resized, mask_binary_resized = UBIRIS_v2_seg_train[0]\n","print(image_resized.shape)\n","print(mask_binary_resized.shape)"],"metadata":{"id":"j3YUsLZqpAGk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Split Data "],"metadata":{"id":"WW3htGsNR34q"}},{"cell_type":"code","source":["def split_train_dataset(train_dataset_all):\n","  train_size= int(len(train_dataset_all)*0.8)\n","  val_size= int(len(train_dataset_all)-train_size)\n","  train_dataset, val_dataset = torch.utils.data.random_split(train_dataset_all, [train_size, val_size], generator=torch.Generator().manual_seed(2022))\n","  \n","  return train_dataset, val_dataset\n","\n","UBIRIS_v2_seg_train_dataset, UBIRIS_v2_seg_val_dataset = split_train_dataset(UBIRIS_v2_seg_train)"],"metadata":{"id":"00Ni9PFPSBOV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(UBIRIS_v2_seg_train_dataset)"],"metadata":{"id":"DaRZKBGqxyNJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(UBIRIS_v2_seg_val_dataset)"],"metadata":{"id":"fdHm1TTEx3k0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#size = (512,512)\n","train_transform = A.Compose(\n","    [\n","      A.ShiftScaleRotate(shift_limit=0.12, scale_limit=0.15, rotate_limit=90, border_mode=cv2.BORDER_CONSTANT, value=0, p=0.5),\n","      A.HorizontalFlip(p=0.5),\n","     \n","      A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n","      A.RandomGamma(p=0.5),\n","\n","      A.OneOf([\n","          A.ElasticTransform(alpha=52, sigma=31, alpha_affine=31,border_mode=cv2.BORDER_CONSTANT, value=0, p=1),\n","          A.OpticalDistortion(distort_limit=0.55, shift_limit=0.12,border_mode=cv2.BORDER_CONSTANT, value=0, p=1),\n","      ], p=0.5),\n","     \n","      A.OneOf([\n","          A.GaussNoise(p=1),\n","          A.Downscale(p=0.5),\n","      ], p=0.5),\n","      A.Normalize(mean=(0.30213674, 0.35349771, 0.49928186), std=(0.14017686, 0.14544913, 0.17964584)), \n","    ]\n",")\n","\n","val_test_transform = A.Compose(\n","    [\n","     # UBIRIS_v2_seg mean and std\n","     A.Normalize(mean=(0.30213674, 0.35349771, 0.49928186), std=(0.14017686, 0.14544913, 0.17964584)),\n","\n","    ]\n",")"],"metadata":{"id":"vsKk2FygReF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["UBIRIS_v2_seg_train_dataset_to_aug, _ = torch.utils.data.random_split(UBIRIS_v2_seg_train_dataset, \n","                                                                      [300, len(UBIRIS_v2_seg_train_dataset)-300], \n","                                                                      generator=torch.Generator().manual_seed(2022))\n","UBIRIS_v2_seg_train_dataset_aug1 = DatasetAfterSplit(UBIRIS_v2_seg_train_dataset_to_aug, transform=train_transform)\n","\n","UBIRIS_v2_seg_train_dataset_all = torch.utils.data.ConcatDataset([UBIRIS_v2_seg_train_dataset, UBIRIS_v2_seg_train_dataset_aug1])\n","\n","print(len(UBIRIS_v2_seg_train_dataset_aug1))\n","print(len(UBIRIS_v2_seg_train_dataset_all))"],"metadata":{"id":"pFrDxNmRQ_6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["UBIRIS_v2_seg_val_dataset_all = DatasetAfterSplit(UBIRIS_v2_seg_val_dataset, transform=val_test_transform)\n","UBIRIS_v2_seg_test_dataset_all = DatasetAfterSplit(UBIRIS_v2_seg_test, transform=val_test_transform)\n","print(len(UBIRIS_v2_seg_val_dataset_all))\n","print(len(UBIRIS_v2_seg_test_dataset_all))"],"metadata":{"id":"nxuVsJuzRAav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mask_resize_transform = A.Compose(\n","    [\n","     A.Resize(height=400, width=400, interpolation=cv2.INTER_NEAREST),\n","     ToTensorV2()\n","    ]\n",")\n"],"metadata":{"id":"O8XS-bHHvadY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["UBIRIS_v2_seg_train_dataset_all = DatasetMaskTransform(UBIRIS_v2_seg_train_dataset_all, transform=mask_resize_transform)\n","UBIRIS_v2_seg_val_dataset_all = DatasetMaskTransform(UBIRIS_v2_seg_val_dataset_all, transform=mask_resize_transform)\n","UBIRIS_v2_seg_test_dataset_all = DatasetMaskTransform(UBIRIS_v2_seg_test_dataset_all, transform=mask_resize_transform)"],"metadata":{"id":"ZIe_CuiA1tsF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Settings"],"metadata":{"id":"nddvGWXEKGXJ"}},{"cell_type":"markdown","source":["Hugging Face Models:\\\n","apple/deeplabv3-mobilevit-small\\\n","apple/deeplabv3-mobilevit-x-small\\\n","apple/deeplabv3-mobilevit-xx-small"],"metadata":{"id":"i_82laRRqm5N"}},{"cell_type":"code","source":["params = {\n","    'model': \"apple/deeplabv3-mobilevit-small\",\n","    'device': \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n","    'batch_size': 16,\n","    'num_workers': 0,\n","    'lr': 0.0001,\n","    'epochs': 5,\n","    'num_labels': 1,\n","    'label2id':{\n","      'iris': 1,\n","    },\n","    'id2label':{\n","      '1': 'iris',\n","    },\n","}"],"metadata":{"id":"2DiuxzCkPNPL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DataLoader\n"],"metadata":{"id":"-pQu00mRrFcy"}},{"cell_type":"code","source":["train_loader = DataLoader(UBIRIS_v2_seg_train_dataset_all,\n","                          batch_size=params['batch_size'],\n","                          shuffle=True,\n","                          num_workers=params['num_workers'],\n","                          pin_memory=True)\n","\n","val_loader = DataLoader(UBIRIS_v2_seg_val_dataset_all,\n","                          batch_size=params['batch_size'],\n","                          shuffle=True,\n","                          num_workers=params['num_workers'],\n","                          pin_memory=True)\n","\n","test_loader = DataLoader(UBIRIS_v2_seg_test_dataset_all,\n","                         batch_size=params['batch_size'],\n","                         shuffle=True,\n","                         num_workers=params['num_workers'],\n","                         pin_memory=True)"],"metadata":{"id":"nzNHw_WWwArc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fine tuning models"],"metadata":{"id":"hJzBjqSWUQgQ"}},{"cell_type":"code","source":["# HuggingFace MobileViT Model\n","IrisViT_seg_model = MobileViTForSemanticSegmentation.from_pretrained(params['model'])"],"metadata":{"id":"TFWwLHgGOiO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# del pytorch_model\n","# del trainer\n","# del IrisViT_seg_model\n","# torch.cuda.empty_cache()"],"metadata":{"id":"NdPO3D8thPvy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IrisViT_seg_model.segmentation_head.classifier.convolution = nn.Sequential(nn.Conv2d(256, 1, kernel_size=(1,1), stride=(1,1)),\n","                                                                           nn.UpsamplingNearest2d((640, 640)))\n","\n","# Initialize Classifier Weights to 0\n","# IrisViT_seg_model.segmentation_head.classifier.convolution.weight.data.fill_(0.0)\n","# IrisViT_seg_model.segmentation_head.classifier.convolution.bias.data.fill_(0.0)\n","# Change model to fit our task\n","IrisViT_seg_model.config.id2label = params['id2label']\n","IrisViT_seg_model.config.label2id = params['label2id']\n","IrisViT_seg_model.config.num_labels = params['num_labels']\n","\n","\n","model_save_path = r\"./models/segmentation/all_datasets/IrisViT_seg_model_small.pth\"\n","IrisViT_seg_model.load_state_dict(torch.load(model_save_path, map_location=params['device']))\n","\n","\n","IrisViT_seg_model.segmentation_head.classifier.convolution[1] = nn.UpsamplingNearest2d((400, 400))\n","\n","# To GPU\n","IrisViT_seg_model.to(params['device'])"],"metadata":{"id":"UavjY1rsNe83"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(IrisViT_seg_model)\n","# print(IrisViT_seg_model.config)\n","# print(IrisViT_seg_model.segmentation_head.classifier.convolution.weight)\n","# print(IrisViT_seg_model.segmentation_head.classifier.convolution.bias)\n","# print(IrisViT_seg_model.segmentation_head.classifier.convolution.weight.shape)\n","# print(IrisViT_seg_model.segmentation_head.classifier.convolution.bias.shape)"],"metadata":{"id":"Et32I8vBXUZu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for name, param in IrisViT_seg_model.named_parameters():\n","#   print(name)"],"metadata":{"id":"vpxWjEkmBisg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loss Function"],"metadata":{"id":"Xup3GyiaU8Lb"}},{"cell_type":"code","source":["# Copy from https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook\n","class DiceBCELoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceBCELoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = torch.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        intersection = (inputs * targets).sum()                            \n","        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n","        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n","        Dice_BCE = BCE + dice_loss\n","        \n","        return Dice_BCE"],"metadata":{"id":"5lhP7kxzfKRd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Segmentation Evaluation"],"metadata":{"id":"G4vP1sb27iDm"}},{"cell_type":"code","source":["def get_true_false_positive_negative(pred_mask, true_mask):\n","\n","    h,w = true_mask.size()\n","    num_pixel = h*w\n","\n","    pred_mask = pred_mask>0\n","    true_mask = true_mask>0\n","\n","    true_positive = (true_mask & pred_mask).sum()\n","    false_positive = (~true_mask & pred_mask).sum()\n","    true_negative = (~(true_mask | pred_mask)).sum()\n","    false_negative = (true_mask & (~pred_mask)).sum()\n","\n","    return {'true_positive': true_positive/num_pixel,\n","            'false_positive': false_positive/num_pixel,\n","            'true_negative': true_negative/num_pixel,        \n","            'false_negative': false_negative/num_pixel}\n","\n","# [0,1] The lower the better 0 is the best, 1 is the worst\n","def get_E1(batch_size, pred_masks, true_masks):\n","\n","    e1_sum = 0\n","    for i in range(batch_size):\n","      tpfn = get_true_false_positive_negative(pred_masks[i], true_masks[i])\n","      fp, fn = tpfn['false_positive'], tpfn['false_negative']\n","      e1_sum += (fp+fn)\n","\n","    return e1_sum/batch_size\n","\n","# [0,1] The lower the better, 0 is the best, 1 is the worst\n","def get_E2(batch_size, pred_masks, true_masks):\n","\n","    e2_sum = 0\n","    for i in range(batch_size):\n","        tpfn = get_true_false_positive_negative(pred_masks[i], true_masks[i])\n","        fp, fn = tpfn['false_positive'], tpfn['false_negative']\n","        e2_sum += 0.5*(fp+fn)\n","\n","    return e2_sum/batch_size\n","\n","# [0,1] 0 is the worst, 1 is the best, mean higher best, var lower best\n","def get_Precision(batch_size, pred_masks, true_masks):\n","    precision_list=[]\n","\n","    for i in range(batch_size):\n","        tpfn = get_true_false_positive_negative(pred_masks[i], true_masks[i])\n","        tp, fp = tpfn['true_positive'], tpfn['false_positive']\n","        precision = tp/(tp+fp)\n","        precision_list.append(precision)\n","    \n","    precision_mean = torch.mean(torch.FloatTensor(precision_list))\n","    precision_var = torch.var(torch.FloatTensor(precision_list))\n","\n","    return precision_list, precision_mean, precision_var\n","\n","# [0,1] 0 is the worst, 1 is the best, mean higher best, var lower best\n","def get_Recall(batch_size, pred_masks, true_masks):\n","    recall_list = []\n","    for i in range(batch_size):\n","        tpfn = get_true_false_positive_negative(pred_masks[i], true_masks[i])\n","        tp, fn = tpfn['true_positive'], tpfn['false_negative']\n","        recall = tp/(tp+fn)\n","        recall_list.append(recall)\n","    \n","    recall_mean = torch.mean(torch.FloatTensor(recall_list))\n","    recall_var = torch.var(torch.FloatTensor(recall_list))\n","\n","    return recall_list, recall_mean, recall_var\n","\n","# [0,1] 0 is the worst, 1 is the best, mean higher best, var lower best\n","def get_F1(batch_size, pred_masks, true_masks):\n","    f1_list = []\n","    precision_list, _, _, = get_Precision(batch_size, pred_masks, true_masks)\n","    recall_list, _, _, = get_Recall(batch_size, pred_masks, true_masks)\n","    for i in range(batch_size):\n","        f1 = (2*recall_list[i]*precision_list[i])/(recall_list[i]+precision_list[i])\n","        f1_list.append(f1)\n","    \n","    f1_mean = torch.mean(torch.FloatTensor(f1_list))\n","    f1_var = torch.var(torch.FloatTensor(f1_list))\n","\n","    return f1_list, f1_mean, f1_var\n","\n","\n","# [0,1] 0 is the worst, 1 is the best The higher the better\n","def get_mIoU(batch_size, pred_masks, true_masks):\n","    miou_sum = 0\n","    for i in range(batch_size):\n","        tfpn = get_true_false_positive_negative(pred_masks[i], true_masks[i])\n","        tp, fp, fn = tfpn['true_positive'], tfpn['false_positive'], tfpn['false_negative']\n","        if tp+fn+fp == 0:\n","            miou=1\n","        else:\n","            miou=tp/(tp+fn+fp)\n","        miou_sum += miou\n","\n","    return miou_sum/batch_size\n","\n","def evaluate_segmentation(pred_masks, true_masks):\n","\n","    batch_size = true_masks.size()[0]\n","\n","    e1 = get_E1(batch_size,  pred_masks, true_masks)\n","    miou = get_mIoU(batch_size, pred_masks, true_masks)\n","\n","    e2 = get_E2(batch_size,  pred_masks, true_masks)\n","    _, precision_mean, precision_var = get_Precision(batch_size, pred_masks, true_masks)\n","    _, recall_mean, recall_var = get_Recall(batch_size, pred_masks, true_masks)\n","    _, f1_mean, f1_var = get_F1(batch_size, pred_masks, true_masks)\n","\n","    return {'E1': e1, \n","            'mIoU': miou,\n","            'E2': e2,\n","            'Precision_Mean': precision_mean,\n","            'Precision_Var': precision_var, \n","            'Recall_Mean': recall_mean,\n","            'Recall_Var': recall_var, \n","            'F1_Mean': f1_mean,\n","            'F1_Var': f1_var}"],"metadata":{"id":"K2tU77ydXkGA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train, Validation, Test"],"metadata":{"id":"DsXlldC4qMQs"}},{"cell_type":"code","source":["class MetricMonitor:\n","    def __init__(self, float_precision=5):\n","        self.float_precision = float_precision\n","        self.reset()\n","\n","    def reset(self):\n","        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n","\n","    def update(self, metric_name, val):\n","        metric = self.metrics[metric_name]\n","\n","        metric[\"val\"] += val\n","        metric[\"count\"] += 1\n","        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n","\n","    def __str__(self):\n","        return \" | \".join(\n","            [\n","                \"{metric_name}: {avg:.{float_precision}f}\".format(\n","                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n","                )\n","                for (metric_name, metric) in self.metrics.items()\n","            ]\n","        )"],"metadata":{"id":"s_YMEmR0Oc9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(val_loader, model, criterion, epoch, params):\n","    metric_monitor = MetricMonitor()\n","    validate_writer = SummaryWriter('./runs/UBIRIS_v2_seg/deeplabv3-mobilevit-small/validate')\n","    model.eval()\n","    stream = tqdm(val_loader)\n","    with torch.no_grad():\n","        for i, (images, masks) in enumerate(stream, start=0):\n","            images = images.float().to(params[\"device\"], non_blocking=True)\n","            masks = masks.float().to(params[\"device\"], non_blocking=True)\n","            output = model(images)\n","            logits = output.logits\n","            \n","            probabilities_writer = torch.sigmoid(logits)\n","            predicted_masks_writer = (probabilities_writer >= 0.5).float() * 1\n","\n","            # Record all masks\n","            validate_writer.add_images('validate_predicted_iris_masks/Epoch {epoch}, Batch {batch}'.format(epoch=epoch, batch=i), \n","                                        predicted_masks_writer, global_step=epoch, walltime=None, dataformats='NCHW')\n","\n","            probabilities = torch.sigmoid(logits.squeeze(1))\n","            predicted_masks = (probabilities >= 0.5).float() * 1\n","\n","            loss = criterion(logits, masks)\n","            evaluations = evaluate_segmentation(predicted_masks, masks.squeeze(1))\n","\n","            # tag, scalar_value, global_step=None, walltime=None\n","            validate_writer.add_scalar('validate/Loss', loss.item(), global_step=epoch)\n","            validate_writer.add_scalar('validate/E1', evaluations['E1'].item(), global_step=epoch)\n","            validate_writer.add_scalar('validate/E2', evaluations['E2'].item(), global_step=epoch)\n","            validate_writer.add_scalar('validate/mIoU', evaluations['mIoU'].item(), global_step=epoch)\n","            validate_writer.add_scalars('validate/Precision_Mean_and_Var', {'Validate_Precision_Mean':evaluations['Precision_Mean'].item(),\n","                                                                            'Validate_Precision_Var':evaluations['Precision_Var'].item()}, global_step=epoch)\n","            validate_writer.add_scalars('validate/Recall_Mean_and_Var', {'Validate_Recall_Mean':evaluations['Recall_Mean'].item(),\n","                                                                        'Validate_Recall_Var':evaluations['Recall_Var'].item()}, global_step=epoch)\n","            validate_writer.add_scalars('validate/F1_Mean_and_Var', {'Validate_F1_Mean':evaluations['F1_Mean'].item(),\n","                                                                     'Validate_F1_Var':evaluations['F1_Var'].item()}, global_step=epoch)\n","\n","            metric_monitor.update(\"Loss\", loss.item())\n","            metric_monitor.update(\"E1\", evaluations['E1'].item())\n","            metric_monitor.update(\"mIoU\",  evaluations['mIoU'].item())\n","\n","            stream.set_description(\n","                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n","            )\n","\n","def test(test_loader, model, criterion, epoch, params):\n","    metric_monitor = MetricMonitor()\n","    test_writer = SummaryWriter('./runs/UBIRIS_v2_seg/deeplabv3-mobilevit-small/test')\n","    model.eval()\n","    stream = tqdm(test_loader)\n","    with torch.no_grad():\n","        for i, (images, masks) in enumerate(stream, start=0):\n","            images = images.float().to(params[\"device\"], non_blocking=True)\n","            masks = masks.float().to(params[\"device\"], non_blocking=True)\n","            output = model(images)\n","            logits = output.logits\n","\n","            probabilities_writer = torch.sigmoid(logits)\n","            predicted_masks_writer = (probabilities_writer >= 0.5).float() * 1\n","\n","            # Record all masks\n","            test_writer.add_images('test_predicted_iris_masks/Epoch {epoch}, Batch {batch}'.format(epoch=epoch, batch=i), \n","                                    predicted_masks_writer, global_step=epoch, walltime=None, dataformats='NCHW')\n","\n","            probabilities = torch.sigmoid(logits.squeeze(1))\n","            predicted_masks = (probabilities >= 0.5).float() * 1\n","\n","            loss = criterion(logits, masks)\n","            evaluations = evaluate_segmentation(predicted_masks, masks.squeeze(1))\n","\n","            # tag, scalar_value, global_step=None, walltime=None\n","            test_writer.add_scalar('test/Loss', loss.item(), global_step=epoch)\n","            test_writer.add_scalar('test/E1', evaluations['E1'].item(), global_step=epoch)\n","            test_writer.add_scalar('test/E2', evaluations['E2'].item(), global_step=epoch)\n","            test_writer.add_scalar('test/mIoU', evaluations['mIoU'].item(), global_step=epoch)\n","            test_writer.add_scalars('test/Precision_Mean_and_Var', {'Test_Precision_Mean':evaluations['Precision_Mean'].item(),\n","                                                                    'Test_Precision_Var':evaluations['Precision_Var'].item()}, global_step=epoch)\n","            test_writer.add_scalars('test/Recall_Mean_and_Var', {'Test_Recall_Mean':evaluations['Recall_Mean'].item(),\n","                                                                 'Test_Recall_Var':evaluations['Recall_Var'].item()}, global_step=epoch)\n","            test_writer.add_scalars('test/F1_Mean_and_Var', {'Test_F1_Mean':evaluations['F1_Mean'].item(),\n","                                                             'Test_F1_Var':evaluations['F1_Var'].item()}, global_step=epoch)\n","\n","            metric_monitor.update(\"Loss\", loss.item())\n","            metric_monitor.update(\"E1\", evaluations['E1'].item())\n","            metric_monitor.update(\"mIoU\",  evaluations['mIoU'].item())\n","\n","            stream.set_description(\n","                \"Epoch: {epoch}. Test. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n","            )\n","\n","def train(train_loader, model, criterion, optimizer, epoch, params):\n","    metric_monitor = MetricMonitor()\n","    train_writer = SummaryWriter('./runs/UBIRIS_v2_seg/deeplabv3-mobilevit-small/train')\n","    model.train()\n","    stream = tqdm(train_loader)\n","    for i, (images, masks) in enumerate(stream, start=0):\n","        images = images.float().to(params['device'], non_blocking=True)\n","        masks = masks.float().to(params['device'], non_blocking=True)\n","        output = model(images)\n","        logits = output.logits\n","\n","        probabilities_writer = torch.sigmoid(logits)\n","        predicted_masks_writer = (probabilities_writer >= 0.5).float() * 1\n","\n","        # Record all masks\n","        train_writer.add_images('train_predicted_iris_masks/Epoch {epoch}, Batch {batch}'.format(epoch=epoch, batch=i), \n","                                predicted_masks_writer, global_step=epoch, walltime=None, dataformats='NCHW')\n","\n","        probabilities = torch.sigmoid(logits.squeeze(1))\n","        predicted_masks = (probabilities >= 0.5).float() * 1\n","        loss = criterion(logits, masks)\n","        evaluations = evaluate_segmentation(predicted_masks, masks.squeeze(1))\n","\n","        # tag, scalar_value, global_step=None, walltime=None\n","        train_writer.add_scalar('train/Loss', loss.item(), global_step=epoch)\n","        train_writer.add_scalar('train/E1', evaluations['E1'].item(), global_step=epoch)\n","        train_writer.add_scalar('train/E2', evaluations['E2'].item(), global_step=epoch)\n","        train_writer.add_scalar('train/mIoU', evaluations['mIoU'].item(), global_step=epoch)\n","        train_writer.add_scalars('train/Precision_Mean_and_Var', {'Train_Precision_Mean':evaluations['Precision_Mean'].item(),\n","                                                                  'Train_Precision_Var':evaluations['Precision_Var'].item()}, global_step=epoch)\n","        train_writer.add_scalars('train/Recall_Mean_and_Var', {'Train_Recall_Mean':evaluations['Recall_Mean'].item(),\n","                                                               'Train_Recall_Var':evaluations['Recall_Var'].item()}, global_step=epoch)\n","        train_writer.add_scalars('train/F1_Mean_and_Var', {'Train_F1_Mean':evaluations['F1_Mean'].item(),\n","                                                           'Train_F1_Var':evaluations['F1_Var'].item()}, global_step=epoch)\n","\n","        metric_monitor.update(\"Loss\", loss.item())\n","        metric_monitor.update(\"E1\", evaluations['E1'].item())\n","        metric_monitor.update(\"mIoU\",  evaluations['mIoU'].item())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        stream.set_description(\n","            \"Epoch: {epoch}. Train. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n","        )"],"metadata":{"id":"mVML7w7_RCU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_validate_test(model, train_loader, val_loader, params):\n","    criterion = DiceBCELoss().to(params['device'])\n","    # # Freeze layers by not tracking gradients\n","    # for param in model.parameters():\n","    #     param.requires_grad = False\n","    # model.segmentation_head.classifier.convolution[0].weight.requires_grad = True\n","    # model.segmentation_head.classifier.convolution[0].bias.requires_grad = True\n","\n","    # optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters())) #, lr=params['lr'], weight_decay=0.0001\n","    optimizer = optim.AdamW(model.parameters())#, lr=params['lr'], weight_decay=0.0001\n","    for epoch in range(params[\"epochs\"]):\n","        train(train_loader, model, criterion, optimizer, epoch, params)\n","        validate(val_loader, model, criterion, epoch, params)\n","    test(test_loader, model, criterion, 0, params)\n","    return model"],"metadata":{"id":"1zSSjtcZREFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IrisViT_seg_model_trained = train_validate_test(IrisViT_seg_model, train_loader=train_loader, val_loader=val_loader, params=params)"],"metadata":{"id":"d397AKfKRx7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(model, params, test_loader):\n","    model.eval()\n","    predictions = []\n","    with torch.no_grad():\n","        for images, masks in test_loader:\n","            images = images.to(params[\"device\"], non_blocking=True)\n","            output = model(images)\n","            logits = output.logits\n","            probabilities = torch.sigmoid(logits.squeeze(1))\n","            predicted_masks = (probabilities >= 0.5).float() * 1\n","            predicted_masks = predicted_masks.cpu().numpy()\n","            for predicted_mask, original_mask in zip(\n","                predicted_masks, masks.squeeze(0).numpy()\n","            ):\n","                predictions.append((predicted_mask, original_mask))\n","    return predictions"],"metadata":{"id":"CypqNqRLEk6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = predict(IrisViT_seg_model_trained, params, test_loader=test_loader)"],"metadata":{"id":"Q2Zep4DDFqRU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualize(image, mask):\n","    fig, ax =  plt.subplots(nrows=1, ncols=2, figsize=(5,5))\n","    ax[0].axis('off')\n","    ax[1].axis('off')\n","    ax[0].imshow(image)\n","    ax[1].imshow(mask)\n"],"metadata":{"id":"fTnAC29V9Mru"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_mask, masks = predictions[0]\n","visualize(predicted_mask, masks.squeeze(0))"],"metadata":{"id":"mjlsFOQcHLqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir './runs/UBIRIS_v2_seg/deeplabv3-mobilevit-small/train'"],"metadata":{"id":"CgOHMEdQPTcH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir './runs/UBIRIS_v2_seg/deeplabv3-mobilevit-small/validate'"],"metadata":{"id":"JBVLKCmbTZAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir './runs/UBIRIS_v2_seg/deeplabv3-mobilevit-small/test'"],"metadata":{"id":"QCtCgHkYTYzO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_save_path = r\"./models/segmentation/UBIRIS_v2_seg/IrisViT_seg_model_small.pth\"\n","torch.save(IrisViT_seg_model_trained.state_dict(), model_save_path)"],"metadata":{"id":"HPw7-LZPqrdo"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"collapsed_sections":["Xup3GyiaU8Lb","G4vP1sb27iDm"]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}